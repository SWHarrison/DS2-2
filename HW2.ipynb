{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "Build and train a MLP Model to classify Mnist dataset  \n",
    "1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.  \n",
    "2- Normalize data by rescaling them to (0,1)  \n",
    "3- Convert label arrays to 1-hot representation (keras.utils.to_categorical)  \n",
    "4- Define Model  \n",
    "Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)  \n",
    "Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)  \n",
    "Outout Layer: Fully Connected + Softmax Activition  \n",
    "Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:  \n",
    "Conv2D(32, kernel_size=(3, 3), activation='relu')  \n",
    "Conv2D(64, kernel_size=(3, 3), activation='relu')  \n",
    "MaxPooling2D(pool_size=(2, 2))  \n",
    "Dense(128, activation='relu')  \n",
    "Dense(num_classes, activation='softmax')  \n",
    "Also build another model with BatchNormalization and Dropout. Compare these two CNN + MLP models performance for test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/samharrison/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/samharrison/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/samharrison/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/samharrison/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/samharrison/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/samharrison/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/samharrison/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[7 2 1 ... 4 5 6]\n",
      "(60000, 784) train samples\n",
      "(10000, 784) test samples\n"
     ]
    }
   ],
   "source": [
    "classes = 10\n",
    "batch_size = 256\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "\n",
    "# convert into binary class matrix\n",
    "y_train = keras.utils.to_categorical(y_train, classes)\n",
    "y_test = keras.utils.to_categorical(y_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# try different dropout rates to see how it is affected\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 9.3219 - acc: 0.4181 - val_loss: 8.6314 - val_acc: 0.4624\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 7.2720 - acc: 0.5469 - val_loss: 6.8051 - val_acc: 0.5763\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 6.8372 - acc: 0.5748 - val_loss: 6.2592 - val_acc: 0.6111\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 6.6645 - acc: 0.5855 - val_loss: 5.9900 - val_acc: 0.6264\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 6.5727 - acc: 0.5914 - val_loss: 6.6345 - val_acc: 0.5878\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 6.7373 - acc: 0.5815 - val_loss: 6.4336 - val_acc: 0.6005\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 6.2657 - acc: 0.6107 - val_loss: 5.5070 - val_acc: 0.6575\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 5.7899 - acc: 0.6403 - val_loss: 5.1016 - val_acc: 0.6829\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 5.4474 - acc: 0.6615 - val_loss: 6.4187 - val_acc: 0.6014\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 5.5496 - acc: 0.6553 - val_loss: 4.9433 - val_acc: 0.6930\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 5.5359 - acc: 0.6563 - val_loss: 5.6067 - val_acc: 0.6520\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 5.5853 - acc: 0.6531 - val_loss: 5.7995 - val_acc: 0.6399\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 5.6852 - acc: 0.6471 - val_loss: 5.9893 - val_acc: 0.6280\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 5.3044 - acc: 0.6706 - val_loss: 5.4454 - val_acc: 0.6620\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 5.5063 - acc: 0.6582 - val_loss: 5.9835 - val_acc: 0.6285\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 5.4949 - acc: 0.6588 - val_loss: 5.8200 - val_acc: 0.6387\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 5.3186 - acc: 0.6698 - val_loss: 5.0281 - val_acc: 0.6880\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 5.5722 - acc: 0.6541 - val_loss: 5.8313 - val_acc: 0.6381\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 5.3923 - acc: 0.6653 - val_loss: 5.7881 - val_acc: 0.6407\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 5.4362 - acc: 0.6624 - val_loss: 5.5428 - val_acc: 0.6559\n",
      "Test loss: 5.5428161094665525\n",
      "Test accuracy: 0.6559\n"
     ]
    }
   ],
   "source": [
    "# What type of optimizer is best?\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history1 = model1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(10,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, classes)\n",
    "y_test = keras.utils.to_categorical(y_test, classes)\n",
    "\n",
    "\n",
    "img_dim = [28,28]\n",
    "x_train = x_train.reshape(x_train.shape[0], img_dim[0], img_dim[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_dim[0], img_dim[1], 1)\n",
    "\n",
    "print(x_train[0].shape)\n",
    "print(x_train[1].shape)\n",
    "print(y_train[0].shape)\n",
    "print(y_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 161s 3ms/step - loss: 3.2433 - acc: 0.7699 - val_loss: 0.0726 - val_acc: 0.9776\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 170s 3ms/step - loss: 0.0482 - acc: 0.9854 - val_loss: 0.0500 - val_acc: 0.9845\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 173s 3ms/step - loss: 0.0219 - acc: 0.9933 - val_loss: 0.0549 - val_acc: 0.9845\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0583 - val_acc: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 162s 3ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0540 - val_acc: 0.9853\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train, y_train,\n",
    "                   batch_size = batch_size,\n",
    "                   epochs = epochs,\n",
    "                   verbose = 1,\n",
    "                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 24, 24, 64)        256       \n",
      "=================================================================\n",
      "Total params: 19,200\n",
      "Trainable params: 19,008\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer max_pooling2d_7: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9931b3c80a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer max_pooling2d_7: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "'''model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])'''\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "print(model3.summary())\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model3.compile(loss=categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
